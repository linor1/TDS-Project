{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast cancer dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split# Load the dataset into a pandas DataFrame\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast cancer dataset-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original feature values:\n",
      "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n",
      "\n",
      "Processed feature values:\n",
      "[[5. 0. 5. ... 9. 5. 4.]\n",
      " [6. 2. 6. ... 6. 2. 2.]\n",
      " [6. 3. 5. ... 8. 4. 2.]\n",
      " ...\n",
      " [4. 6. 4. ... 4. 1. 1.]\n",
      " [6. 6. 6. ... 9. 4. 4.]\n",
      " [0. 5. 0. ... 0. 2. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, KBinsDiscretizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a pipeline for preprocessing the features\n",
    "preprocessor = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('discretizer', KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform'))\n",
    "])\n",
    "\n",
    "# Preprocess the features using the pipeline\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Print the original and processed feature values for the first five rows\n",
    "print(\"Original feature values:\")\n",
    "print(X)\n",
    "print(\"\\nProcessed feature values:\")\n",
    "print(X_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/markdown"
   },
   "source": [
    "## Breast cancer dataset - split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast cancer dataset - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Train a decision tree on the training set\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print the accuracy score on the test set\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred)*100\n",
    "print(\"Accuracy:\", round(acc,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast cancer dataset - chi squared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature names:  ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split# Load the dataset into a pandas DataFrame\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "breast_cancer_data = load_breast_cancer()\n",
    "print(\"feature names: \", breast_cancer_data.feature_names)\n",
    "df = pd.DataFrame(data=breast_cancer_data.data, columns=breast_cancer_data.feature_names)\n",
    "df['target'] = breast_cancer_data.target\n",
    "\n",
    "# Create a Pandas dataframe from the data\n",
    "#df = pd.DataFrame(data=breast_cancer_data.data, columns=breast_cancer_data.feature_names)\n",
    "#X, y = breast_cancer_data.data, breast_cancer_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]  # Select all columns except the last one\n",
    "y = df.iloc[:, -1]   # Select the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: target, dtype: int32"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "chi_scores = chi2(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.66104917e+02, 9.38975081e+01, 2.01110286e+03, 5.39916559e+04,\n",
       "        1.49899264e-01, 5.40307549e+00, 1.97123536e+01, 1.05440354e+01,\n",
       "        2.57379775e-01, 7.43065536e-05, 3.46752472e+01, 9.79353970e-03,\n",
       "        2.50571896e+02, 8.75850471e+03, 3.26620664e-03, 6.13785332e-01,\n",
       "        1.04471761e+00, 3.05231563e-01, 8.03633831e-05, 6.37136566e-03,\n",
       "        4.91689157e+02, 1.74449400e+02, 3.66503542e+03, 1.12598432e+05,\n",
       "        3.97365694e-01, 1.93149220e+01, 3.95169151e+01, 1.34854195e+01,\n",
       "        1.29886140e+00, 2.31522407e-01]),\n",
       " array([8.01397628e-060, 3.32292194e-022, 0.00000000e+000, 0.00000000e+000,\n",
       "        6.98631644e-001, 2.01012999e-002, 9.00175712e-006, 1.16563638e-003,\n",
       "        6.11926026e-001, 9.93122221e-001, 3.89553429e-009, 9.21168192e-001,\n",
       "        1.94877489e-056, 0.00000000e+000, 9.54425121e-001, 4.33366115e-001,\n",
       "        3.06726812e-001, 5.80621137e-001, 9.92847410e-001, 9.36379753e-001,\n",
       "        6.11324751e-109, 7.89668299e-040, 0.00000000e+000, 0.00000000e+000,\n",
       "        5.28452867e-001, 1.10836762e-005, 3.25230064e-010, 2.40424384e-004,\n",
       "        2.54421307e-001, 6.30397277e-001]))"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = pd.Series(chi_scores[1],index = X.columns)\n",
    "p_values.sort_values(ascending = False , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_values.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean fractal dimension      9.931222e-01\n",
      "symmetry error              9.928474e-01\n",
      "smoothness error            9.544251e-01\n",
      "fractal dimension error     9.363798e-01\n",
      "texture error               9.211682e-01\n",
      "mean smoothness             6.986316e-01\n",
      "worst fractal dimension     6.303973e-01\n",
      "mean symmetry               6.119260e-01\n",
      "concave points error        5.806211e-01\n",
      "worst smoothness            5.284529e-01\n",
      "compactness error           4.333661e-01\n",
      "concavity error             3.067268e-01\n",
      "worst symmetry              2.544213e-01\n",
      "mean compactness            2.010130e-02\n",
      "mean concave points         1.165636e-03\n",
      "worst concave points        2.404244e-04\n",
      "worst compactness           1.108368e-05\n",
      "mean concavity              9.001757e-06\n",
      "radius error                3.895534e-09\n",
      "worst concavity             3.252301e-10\n",
      "mean texture                3.322922e-22\n",
      "worst texture               7.896683e-40\n",
      "perimeter error             1.948775e-56\n",
      "mean radius                 8.013976e-60\n",
      "worst radius               6.113248e-109\n",
      "mean perimeter              0.000000e+00\n",
      "worst area                  0.000000e+00\n",
      "worst perimeter             0.000000e+00\n",
      "mean area                   0.000000e+00\n",
      "area error                  0.000000e+00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(p_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove the higher p-value features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['mean fractal dimension' 'symmetry error' 'smoothness error'\\n 'fractal dimension error' 'texture error'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-602-d94c79794583>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean fractal dimension'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'symmetry error'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'smoothness error'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'fractal dimension error'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'texture error'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4306\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4307\u001b[0m         \"\"\"\n\u001b[1;32m-> 4308\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4309\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4310\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4151\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4152\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4153\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4186\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4187\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4188\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4189\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5589\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5590\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5591\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5592\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5593\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['mean fractal dimension' 'symmetry error' 'smoothness error'\\n 'fractal dimension error' 'texture error'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df = df.drop(['mean fractal dimension','symmetry error','smoothness error','fractal dimension error','texture error'],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (largest diff): 81.6%\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a decision tree classifier on the training set\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set and compute accuracy\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "print(f\"Accuracy (largest diff): {round(accuracy_smallest,1)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We dropped five features, and with k-means clustering, we intend to drop the same number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast cancer dataset - K-means clustering part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_features:  30\n",
      "\n",
      "K=5\n",
      "Number of features in the dataset: 30\n",
      "Number of features in the selected dataset (largest diff): 5\n",
      "Accuracy (largest diff): 94.7%\n",
      "Number of features in the selected dataset (smallest diff): 5\n",
      "Accuracy (largest diff): 71.9%\n",
      "\n",
      "K=6\n",
      "Number of features in the dataset: 30\n",
      "Number of features in the selected dataset (largest diff): 6\n",
      "Accuracy (largest diff): 94.7%\n",
      "Number of features in the selected dataset (smallest diff): 6\n",
      "Accuracy (largest diff): 83.3%\n",
      "\n",
      "K=7\n",
      "Number of features in the dataset: 30\n",
      "Number of features in the selected dataset (largest diff): 7\n",
      "Accuracy (largest diff): 93.9%\n",
      "Number of features in the selected dataset (smallest diff): 7\n",
      "Accuracy (largest diff): 85.1%\n",
      "\n",
      "K=8\n",
      "Number of features in the dataset: 30\n",
      "Number of features in the selected dataset (largest diff): 8\n",
      "Accuracy (largest diff): 91.2%\n",
      "Number of features in the selected dataset (smallest diff): 8\n",
      "Accuracy (largest diff): 77.2%\n",
      "\n",
      "K=9\n",
      "Number of features in the dataset: 30\n",
      "Number of features in the selected dataset (largest diff): 9\n",
      "Accuracy (largest diff): 93.0%\n",
      "Number of features in the selected dataset (smallest diff): 9\n",
      "Accuracy (largest diff): 79.8%\n",
      "\n",
      "K=10\n",
      "Number of features in the dataset: 30\n",
      "Number of features in the selected dataset (largest diff): 10\n",
      "Accuracy (largest diff): 93.9%\n",
      "Number of features in the selected dataset (smallest diff): 10\n",
      "Accuracy (largest diff): 78.9%\n",
      "\n",
      "K=11\n",
      "Number of features in the dataset: 30\n",
      "Number of features in the selected dataset (largest diff): 11\n",
      "Accuracy (largest diff): 93.9%\n",
      "Number of features in the selected dataset (smallest diff): 11\n",
      "Accuracy (largest diff): 81.6%\n",
      "\n",
      "K=12\n",
      "Number of features in the dataset: 30\n",
      "Number of features in the selected dataset (largest diff): 12\n",
      "Accuracy (largest diff): 93.0%\n",
      "Number of features in the selected dataset (smallest diff): 12\n",
      "Accuracy (largest diff): 84.2%\n",
      "\n",
      "K=13\n",
      "Number of features in the dataset: 30\n",
      "Number of features in the selected dataset (largest diff): 13\n",
      "Accuracy (largest diff): 93.9%\n",
      "Number of features in the selected dataset (smallest diff): 13\n",
      "Accuracy (largest diff): 78.9%\n",
      "\n",
      "K=14\n",
      "Number of features in the dataset: 30\n",
      "Number of features in the selected dataset (largest diff): 14\n",
      "Accuracy (largest diff): 93.9%\n",
      "Number of features in the selected dataset (smallest diff): 14\n",
      "Accuracy (largest diff): 84.2%\n",
      "\n",
      "K=15\n",
      "Number of features in the dataset: 30\n",
      "Number of features in the selected dataset (largest diff): 15\n",
      "Accuracy (largest diff): 91.2%\n",
      "Number of features in the selected dataset (smallest diff): 15\n",
      "Accuracy (largest diff): 86.0%\n",
      "\n",
      "K=16\n",
      "Number of features in the dataset: 30\n",
      "Number of features in the selected dataset (largest diff): 16\n",
      "Accuracy (largest diff): 91.2%\n",
      "Number of features in the selected dataset (smallest diff): 16\n",
      "Accuracy (largest diff): 86.0%\n",
      "\n",
      "K=17\n",
      "Number of features in the dataset: 30\n",
      "Number of features in the selected dataset (largest diff): 17\n",
      "Accuracy (largest diff): 92.1%\n",
      "Number of features in the selected dataset (smallest diff): 17\n",
      "Accuracy (largest diff): 85.1%\n",
      "\n",
      "K=18\n",
      "Number of features in the dataset: 30\n",
      "Number of features in the selected dataset (largest diff): 18\n",
      "Accuracy (largest diff): 93.9%\n",
      "Number of features in the selected dataset (smallest diff): 18\n",
      "Accuracy (largest diff): 86.8%\n",
      "\n",
      "K=19\n",
      "Number of features in the dataset: 30\n",
      "Number of features in the selected dataset (largest diff): 19\n",
      "Accuracy (largest diff): 93.0%\n",
      "Number of features in the selected dataset (smallest diff): 19\n",
      "Accuracy (largest diff): 84.2%\n",
      "\n",
      "K=20\n",
      "Number of features in the dataset: 30\n",
      "Number of features in the selected dataset (largest diff): 20\n",
      "Accuracy (largest diff): 94.7%\n",
      "Number of features in the selected dataset (smallest diff): 20\n",
      "Accuracy (largest diff): 86.0%\n",
      "\n",
      "K=21\n",
      "Number of features in the dataset: 30\n",
      "Number of features in the selected dataset (largest diff): 21\n",
      "Accuracy (largest diff): 93.9%\n",
      "Number of features in the selected dataset (smallest diff): 21\n",
      "Accuracy (largest diff): 87.7%\n",
      "\n",
      "K=22\n",
      "Number of features in the dataset: 30\n",
      "Number of features in the selected dataset (largest diff): 22\n",
      "Accuracy (largest diff): 92.1%\n",
      "Number of features in the selected dataset (smallest diff): 22\n",
      "Accuracy (largest diff): 91.2%\n",
      "\n",
      "K=23\n",
      "Number of features in the dataset: 30\n",
      "Number of features in the selected dataset (largest diff): 23\n",
      "Accuracy (largest diff): 92.1%\n",
      "Number of features in the selected dataset (smallest diff): 23\n",
      "Accuracy (largest diff): 87.7%\n",
      "\n",
      "K=24\n",
      "Number of features in the dataset: 30\n",
      "Number of features in the selected dataset (largest diff): 24\n",
      "Accuracy (largest diff): 91.2%\n",
      "Number of features in the selected dataset (smallest diff): 24\n",
      "Accuracy (largest diff): 93.0%\n",
      "\n",
      "K=25\n",
      "Number of features in the dataset: 30\n",
      "Number of features in the selected dataset (largest diff): 25\n",
      "Accuracy (largest diff): 93.9%\n",
      "Number of features in the selected dataset (smallest diff): 25\n",
      "Accuracy (largest diff): 93.9%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load the dataset from scikit-learn\n",
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "# Convert the dataset into a pandas DataFrame\n",
    "data = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "\n",
    "# Split the input features and target variable\n",
    "X = data.iloc[:, :]\n",
    "y = breast_cancer.target\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = X.columns.tolist()\n",
    "number_of_features = X.shape[1]\n",
    "print(\"number_of_features: \",number_of_features)\n",
    "for k in range(5, 26):\n",
    "    print(f\"\\nK={k}\")\n",
    "    \n",
    "    # Perform K-means clustering with K clusters\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "\n",
    "    # Compute the mean value of each feature for each cluster\n",
    "    cluster_means = [np.mean(X[kmeans.labels_ == i], axis=0) for i in range(kmeans.n_clusters)]\n",
    "\n",
    "    # Compute the absolute difference in means between clusters for each feature\n",
    "    diff_means = np.abs(np.diff(cluster_means, axis=0))\n",
    "\n",
    "    # Select the features with the largest difference in means between clusters\n",
    "    selected_features = np.argsort(np.sum(diff_means, axis=0))[::-1][:k]\n",
    "    \n",
    "    # Select the features with the smallest difference in means between clusters\n",
    "    selected_features_smallest = np.argsort(np.sum(diff_means, axis=0))[:k]\n",
    "\n",
    "    # Filter the input data to keep only the selected features\n",
    "    X_selected = X.iloc[:, selected_features]\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a decision tree classifier on the training set\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set and compute accuracy\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)*100\n",
    "\n",
    "    print(f\"Number of features in the dataset: {number_of_features}\")\n",
    "    print(f\"Number of features in the selected dataset (largest diff): {len(selected_features)}\")\n",
    "    print(f\"Accuracy (largest diff): {round(accuracy,1)}%\")\n",
    "    \n",
    "    # Filter the input data to keep only the selected features\n",
    "    X_selected_smallest = X.iloc[:, selected_features_smallest]\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train_smallest, X_test_smallest, y_train_smallest, y_test_smallest = train_test_split(X_selected_smallest, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a decision tree classifier on the training set\n",
    "    clf_smallest = DecisionTreeClassifier(random_state=42)\n",
    "    clf_smallest.fit(X_train_smallest, y_train_smallest)\n",
    "\n",
    "    # Make predictions on the test set and compute accuracy\n",
    "    y_pred_smallest = clf_smallest.predict(X_test_smallest)\n",
    "    accuracy_smallest = accuracy_score(y_test_smallest, y_pred_smallest)*100\n",
    "\n",
    "    print(f\"Number of features in the selected dataset (smallest diff): {len(selected_features_smallest)}\")\n",
    "    print(f\"Accuracy (largest diff): {round(accuracy_smallest,1)}%\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for 25 selected features the accuracy is 93.9%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast cancer dataset - K-means clustering part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of columns:  30\n",
      "k =  5 :\n",
      "Accuracy for top 5 features with highest variance: 93.0\n",
      "Accuracy for top 5 features with lowest variance: 73.7\n",
      "k =  6 :\n",
      "Accuracy for top 6 features with highest variance: 93.0\n",
      "Accuracy for top 6 features with lowest variance: 77.2\n",
      "k =  7 :\n",
      "Accuracy for top 7 features with highest variance: 93.0\n",
      "Accuracy for top 7 features with lowest variance: 81.6\n",
      "k =  8 :\n",
      "Accuracy for top 8 features with highest variance: 93.9\n",
      "Accuracy for top 8 features with lowest variance: 83.3\n",
      "k =  9 :\n",
      "Accuracy for top 9 features with highest variance: 93.0\n",
      "Accuracy for top 9 features with lowest variance: 77.2\n",
      "k =  10 :\n",
      "Accuracy for top 10 features with highest variance: 93.9\n",
      "Accuracy for top 10 features with lowest variance: 86.0\n",
      "k =  11 :\n",
      "Accuracy for top 11 features with highest variance: 93.0\n",
      "Accuracy for top 11 features with lowest variance: 87.7\n",
      "k =  12 :\n",
      "Accuracy for top 12 features with highest variance: 93.0\n",
      "Accuracy for top 12 features with lowest variance: 85.1\n",
      "k =  13 :\n",
      "Accuracy for top 13 features with highest variance: 93.9\n",
      "Accuracy for top 13 features with lowest variance: 85.1\n",
      "k =  14 :\n",
      "Accuracy for top 14 features with highest variance: 93.0\n",
      "Accuracy for top 14 features with lowest variance: 84.2\n",
      "k =  15 :\n",
      "Accuracy for top 15 features with highest variance: 91.2\n",
      "Accuracy for top 15 features with lowest variance: 85.1\n",
      "k =  16 :\n",
      "Accuracy for top 16 features with highest variance: 92.1\n",
      "Accuracy for top 16 features with lowest variance: 86.8\n",
      "k =  17 :\n",
      "Accuracy for top 17 features with highest variance: 90.4\n",
      "Accuracy for top 17 features with lowest variance: 85.1\n",
      "k =  18 :\n",
      "Accuracy for top 18 features with highest variance: 91.2\n",
      "Accuracy for top 18 features with lowest variance: 85.1\n",
      "k =  19 :\n",
      "Accuracy for top 19 features with highest variance: 93.0\n",
      "Accuracy for top 19 features with lowest variance: 86.8\n",
      "k =  20 :\n",
      "Accuracy for top 20 features with highest variance: 93.0\n",
      "Accuracy for top 20 features with lowest variance: 85.1\n",
      "k =  21 :\n",
      "Accuracy for top 21 features with highest variance: 92.1\n",
      "Accuracy for top 21 features with lowest variance: 86.8\n",
      "k =  22 :\n",
      "Accuracy for top 22 features with highest variance: 91.2\n",
      "Accuracy for top 22 features with lowest variance: 88.6\n",
      "k =  23 :\n",
      "Accuracy for top 23 features with highest variance: 92.1\n",
      "Accuracy for top 23 features with lowest variance: 92.1\n",
      "k =  24 :\n",
      "Accuracy for top 24 features with highest variance: 93.0\n",
      "Accuracy for top 24 features with lowest variance: 93.9\n",
      "k =  25 :\n",
      "Accuracy for top 25 features with highest variance: 93.0\n",
      "Accuracy for top 25 features with lowest variance: 93.0\n",
      "k =  26 :\n",
      "Accuracy for top 26 features with highest variance: 91.2\n",
      "Accuracy for top 26 features with lowest variance: 93.9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Convert the dataset to a pandas DataFrame\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "\n",
    "X = df.iloc[:, :-1]  # Select all columns except the last one\n",
    "y = df.iloc[:, -1]   # Select the last column\n",
    "print(\"number of columns: \", X.shape[1])\n",
    "\n",
    "# Fit K-means clustering to the data\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Get the cluster labels and centroids\n",
    "labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Compute the variance of each feature within each cluster\n",
    "variances = np.zeros((3, X.shape[1]))\n",
    "for i in range(3):\n",
    "    cluster_data = X[labels == i]\n",
    "    variances[i] = np.var(cluster_data, axis=0)\n",
    "\n",
    "# Select the features with the highest variance within the cluster with the most data points\n",
    "most_common_cluster = np.argmax(np.bincount(labels))\n",
    "for k in range(5, 27):\n",
    "    selected_features = np.argsort(variances[most_common_cluster])[::-1][:k] # select top k features with highest variance\n",
    "    # select the features with the lowest variance within the most common cluster\n",
    "    low_selected_features = np.argsort(variances[most_common_cluster])[:k]  # select top k features with lowest variance\n",
    "    # Use the selected features to transform the data\n",
    "    X_selected = X.iloc[:, selected_features]\n",
    "    low_X_selected = X.iloc[:, low_selected_features]\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a decision tree classifier on the training set\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set and compute accuracy\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)*100\n",
    "    print(\"k = \",k,\":\")\n",
    "    print(f\"Accuracy for top {k} features with highest variance:\", round(accuracy,1))\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(low_X_selected, y, test_size=0.2, random_state=42)\n",
    "    # Train a decision tree classifier on the training set\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Make predictions on the test set and compute accuracy\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)*100\n",
    "    print(f\"Accuracy for top {k} features with lowest variance:\", round(accuracy,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we receved: Accuracy for top 25 features with highest variance: 93%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris dataset - load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Target names: ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the dataset\n",
    "iris = load_iris()\n",
    "X=iris.data\n",
    "y=iris.target\n",
    "# Print the feature names and target names\n",
    "print(\"Feature names:\", iris.feature_names)\n",
    "print(\"Target names:\", iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris dataset - split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Dataset - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Train a decision tree on the training set\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate precision\n",
    "precision = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate recall\n",
    "recall = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate mean squared error using sklearn's mean_squared_error function\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\",round(accuracy,1))\n",
    "print(\"Precision:\", round(precision,1))\n",
    "print(\"Recall:\", round(recall,1))\n",
    "print(\"F1 score:\", round(f1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Load the dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Create a decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Perform 10-fold cross-validation and calculate multiple evaluation metrics\n",
    "scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'neg_mean_squared_error']\n",
    "scores = cross_validate(clf, X, y, scoring=scoring, cv=10, return_train_score=False)\n",
    "\n",
    "# Print the evaluation metric values for each fold\n",
    "print(\"Cross-validation results:\")\n",
    "for i in range(10):\n",
    "    print(\"Fold\", i+1, \"accuracy:\", scores['test_accuracy'][i])\n",
    "    print(\"Fold\", i+1, \"precision:\", scores['test_precision_weighted'][i])\n",
    "    print(\"Fold\", i+1, \"recall:\", scores['test_recall_weighted'][i])\n",
    "    print(\"Fold\", i+1, \"F1 score:\", scores['test_f1_weighted'][i])\n",
    "    print(\"Fold\", i+1, \"mean squared error:\", -scores['test_neg_mean_squared_error'][i])\n",
    "    print()\n",
    "    \n",
    "# Calculate the mean and standard deviation of the evaluation metrics across all folds\n",
    "mean_accuracy = scores['test_accuracy'].mean()\n",
    "mean_precision = scores['test_precision_weighted'].mean()\n",
    "mean_recall = scores['test_recall_weighted'].mean()\n",
    "mean_f1 = scores['test_f1_weighted'].mean()\n",
    "mean_mse = -scores['test_neg_mean_squared_error'].mean()\n",
    "std_accuracy = scores['test_accuracy'].std()\n",
    "std_precision = scores['test_precision_weighted'].std()\n",
    "std_recall = scores['test_recall_weighted'].std()\n",
    "std_f1 = scores['test_f1_weighted'].std()\n",
    "std_mse = scores['test_neg_mean_squared_error'].std()\n",
    "\n",
    "# Print the mean and standard deviation of the evaluation metrics across all folds\n",
    "print(\"Mean cross-validation accuracy:\", mean_accuracy)\n",
    "print(\"Standard deviation of cross-validation accuracy:\", std_accuracy)\n",
    "print(\"Mean cross-validation precision:\", mean_precision)\n",
    "print(\"Standard deviation of cross-validation precision:\", std_precision)\n",
    "print(\"Mean cross-validation recall:\", mean_recall)\n",
    "print(\"Standard deviation of cross-validation recall:\", std_recall)\n",
    "print(\"Mean cross-validation F1 score:\", mean_f1)\n",
    "print(\"Standard deviation of cross-validation F1 score:\", std_f1)\n",
    "print(\"Mean cross-validation mean squared error:\", mean_mse)\n",
    "print(\"Standard deviation of cross-validation mean squared error:\", std_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chi squared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "iris = load_iris()\n",
    "\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "X = df.iloc[:, :-1]  # Select all columns except the last one\n",
    "y = df.iloc[:, -1]   # Select the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)\n",
       "0                5.1               3.5                1.4\n",
       "1                4.9               3.0                1.4\n",
       "2                4.7               3.2                1.3\n",
       "3                4.6               3.1                1.5\n",
       "4                5.0               3.6                1.4"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.2\n",
       "1    0.2\n",
       "2    0.2\n",
       "3    0.2\n",
       "4    0.2\n",
       "Name: petal width (cm), dtype: float64"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (0      0.2\n1      0.2\n2      0.2\n3      0.2\n4      0.2\n      ... \n145    2.3\n146    1.9\n147    2.0\n148    2.3\n149    1.8\nName: petal width (cm), Length: 150, dtype: float64,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-618-1cd11f354a4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mchi2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mchi_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchi2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mchi_scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py\u001b[0m in \u001b[0;36mchi2\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input X must be non-negative.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m     \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mof\u001b[0m \u001b[0mCSR\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \"\"\"\n\u001b[1;32m--> 321\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_input_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[0m_unique_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FN_UNIQUE_LABELS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_unique_labels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[0mys_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: (0      0.2\n1      0.2\n2      0.2\n3      0.2\n4      0.2\n      ... \n145    2.3\n146    1.9\n147    2.0\n148    2.3\n149    1.8\nName: petal width (cm), Length: 150, dtype: float64,)"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "chi_scores = chi2(X,y)\n",
    "chi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of passed values is 30, index implies 3.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-619-b47836083a05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mp_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchi_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mp_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mp_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    348\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m                         raise ValueError(\n\u001b[0m\u001b[0;32m    351\u001b[0m                             \u001b[1;34mf\"Length of passed values is {len(data)}, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m                             \u001b[1;34mf\"index implies {len(index)}.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of passed values is 30, index implies 3."
     ]
    }
   ],
   "source": [
    "p_values = pd.Series(chi_scores[1],index = X.columns)\n",
    "p_values.sort_values(ascending = False , inplace = True)\n",
    "p_values.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age       sex       bmi        bp        s1        s2        s3  \\\n",
      "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
      "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
      "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
      "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
      "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
      "\n",
      "         s4        s5        s6  target  \n",
      "0 -0.002592  0.019908 -0.017646   151.0  \n",
      "1 -0.039493 -0.068330 -0.092204    75.0  \n",
      "2 -0.002592  0.002864 -0.025930   141.0  \n",
      "3  0.034309  0.022692 -0.009362   206.0  \n",
      "4 -0.002592 -0.031991 -0.046641   135.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "# Convert the NumPy array to a pandas DataFrame\n",
    "df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "\n",
    "# Add the target variable to the DataFrame\n",
    "df['target'] = diabetes.target\n",
    "\n",
    "# Print the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "X = df[diabetes.feature_names]  # Select all feature columns\n",
    "y = df['target']   # Select the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  \n",
       "0 -0.002592  0.019908 -0.017646  \n",
       "1 -0.039493 -0.068330 -0.092204  \n",
       "2 -0.002592  0.002864 -0.025930  \n",
       "3  0.034309  0.022692 -0.009362  \n",
       "4 -0.002592 -0.031991 -0.046641  "
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    151.0\n",
       "1     75.0\n",
       "2    141.0\n",
       "3    206.0\n",
       "4    135.0\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Scale the features to be between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Compute the chi-squared scores\n",
    "chi_scores = chi2(X_scaled, y)\n",
    "\n",
    "# Create a pandas Series with the p-values and feature names\n",
    "p_values = pd.Series(chi_scores[1], index=X.columns)\n",
    "\n",
    "# Sort the p-values in descending order\n",
    "p_values_sorted = p_values.sort_values(ascending=False)\n",
    "\n",
    "# Plot the p-values as a bar chart\n",
    "p_values_sorted.plot.bar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 21.570582  , 117.88067633,  27.81452884,  21.54922486,\n",
       "         12.99994253,  12.49458436,  20.76010575,  29.4906842 ,\n",
       "         20.07488764,  13.9680535 ]),\n",
       " array([1.        , 0.99999998, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ]))"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-639-2685d04442fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mp_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchi_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_scaled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mp_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mp_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of labels=120 does not match number of samples=614",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-645-3bd5d934e1e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Train Decision Tree Classifer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#Predict the response for test dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    896\u001b[0m         \"\"\"\n\u001b[0;32m    897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    899\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m             raise ValueError(\"Number of labels=%d does not match \"\n\u001b[0m\u001b[0;32m    282\u001b[0m                              \"number of samples=%d\" % (len(y), n_samples))\n\u001b[0;32m    283\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_weight_fraction_leaf\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of labels=120 does not match number of samples=614"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "# Create Decision Tree classifer object\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "model = model.fit(x_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(x_test)\n",
    "#Evaluation using Accuracy score\n",
    "from sklearn import metrics\n",
    "\n",
    "# Calculate accuracy using sklearn's recall_score function\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate precision\n",
    "precision = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate recall using sklearn's recall_score function\n",
    "recall =metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate F1 score using sklearn's f1_score function\n",
    "f1 = metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"precision:\",precision)\n",
    "print(\"Recall: \",recall)\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "print(\"data: \", diabetes.data)\n",
    "print(\"target: \", diabetes.target)\n",
    "# Create a pandas dataframe with feature data\n",
    "df_features = pd.DataFrame(data=diabetes.data, columns=diabetes.feature_names)\n",
    "\n",
    "# Create a pandas dataframe with target data and rename the column\n",
    "df_target = pd.DataFrame(data=diabetes.target, columns=['target'])\n",
    "\n",
    "# Concatenate the feature and target dataframes horizontally\n",
    "df = pd.concat([df_features, df_target], axis=1)\n",
    "\n",
    "# Print the dataframe\n",
    "print(df.head())\n",
    "print(\"feature names: \", diabetes.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "print(\"data: \", diabetes.data)\n",
    "print(\"target: \", diabetes.target)\n",
    "# Create a pandas dataframe with feature data\n",
    "df_features = pd.DataFrame(data=diabetes.data, columns=diabetes.feature_names)\n",
    "\n",
    "# Create a pandas dataframe with target data and rename the column\n",
    "df_target = pd.DataFrame(data=diabetes.target, columns=['target'])\n",
    "\n",
    "# Concatenate the feature and target dataframes horizontally\n",
    "df = pd.concat([df_features, df_target], axis=1)\n",
    "\n",
    "# Print the dataframe\n",
    "print(df.head())\n",
    "print(\"feature names: \", diabetes.feature_names)\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the diabetes dataset and split it into training and test sets\n",
    "diabetes = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target,test_size=0.2, random_state=0)\n",
    "\n",
    "# Initialize the decision tree regressor and fit it to the training data\n",
    "tree = DecisionTreeRegressor(random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance of the decision tree on the test set\n",
    "y_pred = tree.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Root mean squared error on test set: {rmse}\")\n",
    "\n",
    "# Evaluate the model on the test data and calculate the accuracy\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data by scaling the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train a decision tree regression model on the training data\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test data and calculate the accuracy\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred.round())\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[4 7 5 8 9 2 6 3 0 1]\n",
      "number of features in the dataset:  10\n",
      "number of features in the selected dataset:  10\n",
      "Accuracy: 0.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the Diabetes dataset\n",
    "data = load_diabetes()\n",
    "X, y = data.data, data.target\n",
    "feature_names = data.feature_names\n",
    "number_of_features = X.shape[1]\n",
    "print(number_of_features)\n",
    "\n",
    "# Perform K-means clustering with K=3 clusters\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Compute the mean value of each feature for each cluster\n",
    "cluster_means = [np.mean(X[kmeans.labels_ == i, :], axis=0) for i in range(kmeans.n_clusters)]\n",
    "\n",
    "# Compute the absolute difference in means between clusters for each feature\n",
    "diff_means = np.abs(np.diff(cluster_means, axis=0))\n",
    "\n",
    "# Select the features with the largest difference in means between clusters\n",
    "selected_features = np.argsort(np.sum(diff_means, axis=0))[::-1][:10]\n",
    "\n",
    "# Filter the input data to keep only the selected features\n",
    "X_selected = X[:, selected_features]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a decision tree classifier on the training set\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set and compute accuracy\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "\n",
    "# Print the selected features\n",
    "print(selected_features)\n",
    "selected_feature_names = [feature_names[i] for i in selected_features]\n",
    "print(\"number of features in the dataset: \",number_of_features)\n",
    "print(\"number of features in the selected dataset: \",len(selected_feature_names))\n",
    "print(f\"Accuracy: {round(accuracy, 1)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/markdown"
   },
   "source": [
    "# Wine dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data - wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature names:  ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  target  \n",
       "0                          3.92   1065.0       0  \n",
       "1                          3.40   1050.0       0  \n",
       "2                          3.17   1185.0       0  \n",
       "3                          3.45   1480.0       0  \n",
       "4                          2.93    735.0       0  "
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "wine = load_wine()\n",
    "print(\"feature names: \", wine.feature_names)\n",
    "# Create a Pandas dataframe from the data\n",
    "df = pd.DataFrame(data=wine.data, columns=wine.feature_names)\n",
    "\n",
    "# Add the target variable to the dataframe\n",
    "df['target'] = wine.target\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]  # Select all columns except the last one\n",
    "y = df.iloc[:, -1]   # Select the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  \n",
       "0                          3.92   1065.0  \n",
       "1                          3.40   1050.0  \n",
       "2                          3.17   1185.0  \n",
       "3                          3.45   1480.0  \n",
       "4                          2.93    735.0  "
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: target, dtype: int32"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree - wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "# Create Decision Tree classifer object\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "model = model.fit(x_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"weighted\" parameter is used to calculate the precision \n",
    "for each class and then average them based on their support (the number of samples in each class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "# Calculate accuracy\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate precision\n",
    "precision = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate recall\n",
    "recall = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = metrics.f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "Precision: 0.9\n",
      "Recall: 0.9\n",
      "F1 score: 0.9\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",round(accuracy,1))\n",
    "print(\"Precision:\",round(precision, 1))\n",
    "print(\"Recall:\", round(recall, 1))\n",
    "print(\"F1 score:\", round(f1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chisquared test - wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.44549882e+00, 2.80686046e+01, 7.43380598e-01, 2.93836955e+01,\n",
       "        4.50263809e+01, 1.56230759e+01, 6.33343081e+01, 1.81548480e+00,\n",
       "        9.36828307e+00, 1.09016647e+02, 5.18253981e+00, 2.33898834e+01,\n",
       "        1.65400671e+04]),\n",
       " array([6.56938863e-02, 8.03489047e-07, 6.89567769e-01, 4.16304971e-07,\n",
       "        1.66972759e-10, 4.05034646e-04, 1.76656548e-14, 4.03433989e-01,\n",
       "        9.24066398e-03, 2.12488671e-24, 7.49248322e-02, 8.33587826e-06,\n",
       "        0.00000000e+00]))"
      ]
     },
     "execution_count": 699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "chi_scores = chi2(X,y)\n",
    "chi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAGJCAYAAACab8iUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAzA0lEQVR4nO3deZhkVX3/8feHAVQQBGXUyCJoQIMR+OmIIsTdCG64geAajRJUFGJcyGMSFWPc4hYlEmQRjQooqKiDaFBABYFBFlkVEWXEBdxARBH4/P44t+ianuru6ulzq7rufF7P00/3vXX7ntNLfevUWb5HtomIiMm3zrgrEBERdSSgR0R0RAJ6RERHJKBHRHREAnpEREckoEdEdMS64yp4s80289Zbbz2u4iMiJtJ55513ve2lgx4bW0DfeuutWbFixbiKj4iYSJJ+PNNj6XKJiOiIoQK6pN0lXSHpSkkHD3j89ZIuaD4ulnSbpLvXr25ERMxkzoAuaQlwKLAHsD2wr6Tt+6+x/R7bO9neCfhn4HTbv26hvhERMYNhWug7A1favsr2LcCxwJ6zXL8v8OkalYuIiOENE9A3B67pO17ZnFuNpA2A3YETFl61iIiYj2ECugacmylF49OAb8/U3SJpP0krJK247rrrhq1jREQMYZiAvhLYsu94C+DaGa7dh1m6W2wfbnuZ7WVLlw6cRhkREWtomIB+LrCtpG0krU8J2idNv0jS3YBHA1+oW8WIiBjGnAuLbN8q6QDgFGAJcJTtSyTt3zx+WHPpM4Gv2r5poZXa+uAvz/t7rn7nUxZabETERBtqpajt5cDyaecOm3b8MeBjtSoWERHzk5WiEREdkYAeEdERCegRER2RgB4R0REJ6BERHZGAHhHREQnoEREdkYAeEdERCegRER2RgB4R0REJ6BERHZGAHhHREQnoEREdkYAeEdERCegRER2RgB4R0REJ6BERHZGAHhHREQnoEREdkYAeEdERCegRER0xVECXtLukKyRdKengGa55jKQLJF0i6fS61YyIiLmsO9cFkpYAhwJPBFYC50o6yfalfddsAvw3sLvtn0i6Z0v1jYiIGQzTQt8ZuNL2VbZvAY4F9px2zfOAE23/BMD2L+tWMyIi5jJMQN8cuKbveGVzrt92wKaSTpN0nqQX1apgREQMZ84uF0ADznnAfR4KPB64C3CWpO/Y/v4qN5L2A/YD2GqrreZf24iImNEwLfSVwJZ9x1sA1w645iu2b7J9PXAGsOP0G9k+3PYy28uWLl26pnWOiIgBhgno5wLbStpG0vrAPsBJ0675AvA3ktaVtAHwcOCyulWNiIjZzNnlYvtWSQcApwBLgKNsXyJp/+bxw2xfJukrwEXA7cARti9us+IREbGqYfrQsb0cWD7t3GHTjt8DvKde1SIiYj6yUjQioiMS0CMiOiIBPSKiIxLQIyI6IgE9IqIjEtAjIjoiAT0ioiMS0CMiOiIBPSKiIxLQIyI6IgE9IqIjEtAjIjoiAT0ioiMS0CMiOiIBPSKiIxLQIyI6IgE9IqIjEtAjIjoiAT0ioiMS0CMiOiIBPSKiI4YK6JJ2l3SFpCslHTzg8cdI+p2kC5qPf6tf1YiImM26c10gaQlwKPBEYCVwrqSTbF867dJv2n5qC3WMiIghDNNC3xm40vZVtm8BjgX2bLdaERExX8ME9M2Ba/qOVzbnpttF0oWSTpb0oCq1i4iIoc3Z5QJowDlPO/4ucF/bv5f0ZODzwLar3UjaD9gPYKuttppfTSMiYlbDtNBXAlv2HW8BXNt/ge0bbP+++Xo5sJ6kzabfyPbhtpfZXrZ06dIFVDsiIqYbJqCfC2wraRtJ6wP7ACf1XyDp3pLUfL1zc99f1a5sRETMbM4uF9u3SjoAOAVYAhxl+xJJ+zePHwY8B3iFpFuBm4F9bE/vlomIiBYN04fe60ZZPu3cYX1ffxj4cN2qRUTEfGSlaERERySgR0R0RAJ6RERHJKBHRHREAnpEREckoEdEdEQCekRERySgR0R0RAJ6RERHJKBHRHREAnpEREckoEdEdEQCekRERySgR0R0RAJ6RERHJKBHRHREAnpEREckoEdEdEQCekRERySgR0R0RAJ6RERHJKBHRHTEUAFd0u6SrpB0paSDZ7nuYZJuk/ScelWMiIhhzBnQJS0BDgX2ALYH9pW0/QzXvQs4pXYlIyJibusOcc3OwJW2rwKQdCywJ3DptOteDZwAPKxqDVuy9cFfnvf3XP3Op7RQk4iIOobpctkcuKbveGVz7g6SNgeeCRw2240k7SdphaQV11133XzrGhERsxgmoGvAOU87/gDwRtu3zXYj24fbXmZ72dKlS4esYkREDGOYLpeVwJZ9x1sA1067ZhlwrCSAzYAnS7rV9udrVDIiIuY2TEA/F9hW0jbAT4F9gOf1X2B7m97Xkj4GfCnBPCJitOYM6LZvlXQAZfbKEuAo25dI2r95fNZ+84iIGI1hWujYXg4sn3ZuYCC3/XcLr1ZERMxXVopGRHREAnpEREckoEdEdEQCekRERySgR0R0RAJ6RERHJKBHRHREAnpEREckoEdEdEQCekRERySgR0R0RAJ6RERHJKBHRHREAnpEREckoEdEdEQCekRERySgR0R0RAJ6RERHJKBHRHREAnpEREckoEdEdMRQAV3S7pKukHSlpIMHPL6npIskXSBphaTd6lc1IiJms+5cF0haAhwKPBFYCZwr6STbl/Zddipwkm1L2gE4HnhgGxWOiIjBhmmh7wxcafsq27cAxwJ79l9g+/e23RxuCJiIiBipYQL65sA1fccrm3OrkPRMSZcDXwZeOuhGkvZrumRWXHfddWtS34iImMEwAV0Dzq3WArf9OdsPBJ4BvG3QjWwfbnuZ7WVLly6dV0UjImJ2wwT0lcCWfcdbANfOdLHtM4D7S9psgXWLiIh5GCagnwtsK2kbSesD+wAn9V8g6S8lqfn6IcD6wK9qVzYiImY25ywX27dKOgA4BVgCHGX7Ekn7N48fBjwbeJGkPwM3A8/tGySNiIgRmDOgA9heDiyfdu6wvq/fBbyrbtUiImI+slI0IqIjEtAjIjoiAT0ioiMS0CMiOiIBPSKiIxLQIyI6IgE9IqIjEtAjIjoiAT0ioiMS0CMiOiIBPSKiIxLQIyI6IgE9IqIjEtAjIjoiAT0ioiMS0CMiOiIBPSKiIxLQIyI6IgE9IqIjEtAjIjoiAT0ioiOGCuiSdpd0haQrJR084PHnS7qo+ThT0o71qxoREbOZM6BLWgIcCuwBbA/sK2n7aZf9CHi07R2AtwGH165oRETMbpgW+s7Albavsn0LcCywZ/8Fts+0/Zvm8DvAFnWrGRERcxkmoG8OXNN3vLI5N5O/B04e9ICk/SStkLTiuuuuG76WERExp2ECugac88ALpcdSAvobBz1u+3Dby2wvW7p06fC1jIiIOa07xDUrgS37jrcArp1+kaQdgCOAPWz/qk71IiJiWMO00M8FtpW0jaT1gX2Ak/ovkLQVcCLwQtvfr1/NiIiYy5wtdNu3SjoAOAVYAhxl+xJJ+zePHwb8G3AP4L8lAdxqe1l71Y6IiOmG6XLB9nJg+bRzh/V9/TLgZXWrFhER85GVohERHZGAHhHREQnoEREdkYAeEdERCegRER2RgB4R0REJ6BERHZGAHhHREQnoEREdkYAeEdERCegRER2RgB4R0REJ6BERHZGAHhHREQnoEREdkYAeEdERCegRER2RgB4R0REJ6BERHZGAHhHREQnoEREdMVRAl7S7pCskXSnp4AGPP1DSWZL+JOl19asZERFzWXeuCyQtAQ4FngisBM6VdJLtS/su+zXwGuAZbVQyIiLmNkwLfWfgSttX2b4FOBbYs/8C27+0fS7w5xbqGBERQxgmoG8OXNN3vLI5N2+S9pO0QtKK6667bk1uERERMxgmoGvAOa9JYbYPt73M9rKlS5euyS0iImIGwwT0lcCWfcdbANe2U52IiFhTwwT0c4FtJW0jaX1gH+CkdqsVERHzNecsF9u3SjoAOAVYAhxl+xJJ+zePHybp3sAKYGPgdkkHAdvbvqG9qkdERL85AzqA7eXA8mnnDuv7+ueUrpiIiBiTrBSNiOiIBPSIiI4Yqssl1tzWB3953t9z9Tuf0kJNIqLr0kKPiOiItNA7Iu8EIiIt9IiIjkhAj4joiAT0iIiOSECPiOiIBPSIiI5IQI+I6IgE9IiIjkhAj4joiAT0iIiOSECPiOiIBPSIiI5IQI+I6IgE9IiIjkhAj4joiAT0iIiOSECPiOiIoTa4kLQ78EFgCXCE7XdOe1zN408G/gD8ne3vVq5rLALZSCNi8ZqzhS5pCXAosAewPbCvpO2nXbYHsG3zsR/wkcr1jIiIOQzT5bIzcKXtq2zfAhwL7Dntmj2Bj7v4DrCJpL+oXNeIiJjFMF0umwPX9B2vBB4+xDWbAz/rv0jSfpQWPMDvJV0xr9rCZsD1gx7Qu+Z5pzUop3IZoypnrL+zUZZT2SjK6dLP0rVyFvPPct+ZHhgmoGvAOa/BNdg+HDh8iDIHV0RaYXvZmn7/2lhOl36WrpXTpZ+la+VM6s8yTJfLSmDLvuMtgGvX4JqIiGjRMAH9XGBbSdtIWh/YBzhp2jUnAS9S8Qjgd7Z/Nv1GERHRnjm7XGzfKukA4BTKtMWjbF8iaf/m8cOA5ZQpi1dSpi2+pKX6rnF3zVpcTpd+lq6V06WfpWvlTOTPInu1ru6IiJhAWSkaEdERCegRER2RgB4R0REJ6BEDSFpH0sbjrkfEfCz6gC5pV0lfk/R9SVdJ+pGkq1ooZy9JGzVf/4ukEyU9pIVy7ivpCc3Xd+mVWene35N00YCP70m6qFY5feWN6nd2f0l3ar5+jKTXSNqkhXI+JWljSRsClwJXSHp97XJGYYTPm6dKOl/SryXdIOlGSTdULuPdzd9lPUmnSrpe0gtqltGU85+SHlT7vgPKuZekIyWd3BxvL+nvq9zc9qL+AC6nJP+6J3CP3kcL5VzUfN4N+CYlP83Zlct4OWVe/w+b422BUyve/76zfUzi76y5/wWUKbZ/CfwQeD+wvI1yms/PB94HrNf7GSvd/0bghpk+Kv8so3reXAnsQDNjro2Pvr/LM4FjgLsDF7ZQzsuAbwNnA/sDd2vp5zkZ2Lv3MzT/29+rce9F30KnLFI62fYvbf+q99FCObc1n58CfMT2F4D1K5fxKmBXyhMY2z+gPOGqsP3j3gfwR+DBzcfNzbnaRvE7A7jd9q2UJ/QHbP8j0Ebyt/UkrQc8A/iC7T8zIIXFmrK9ke2NgQ8AB1PyHW0BvBH491rlNEb1vLkGuNhNZGrJes3nJwOftv3rNgqxfYTtXYEXAVsDFzXv2h5buajNbB8P3N6UeytTz6UFGSof+jj0vXX/hqT3ACcCf+o97vr51n8q6X+AJwDvat7i137B+5PtW0r6eJC0LhUDRo+kvYH3AKdR8ux8SNLrbX+2clGj+J0B/FnSvsCLgac159ab5fo19T/A1cCFwBmS7kvz4lvZk2z3J7j7iKSzgXcv9MZjeN68AVgu6fRp5byvYhlflHQ5cDPwSklLKQ2W6pp04Q9sPq6n/C+8VtI/2N6nUjE3SboHzXO/t7q+xo0X7cIiSd+Y5WHbflzl8jYAdqe89flBk/73wba/WrGMdwO/pbQAXg28ErjU9ptqldGUcyHwRNu/bI6XAv9ne8fK5bT+O2vK2Z7yFvgs25+WtA3wXE/baKUNktZtWlA173kmZY+BYylP6n2BV9l+ZIV7j/p581Xg98D3aFqcTUFvrVzOppRuqduaMY6NbP+8chnvozQYvg4cafucvseusP2ASuU8BPgQ8NfAxcBS4Dm2FzzOtWgD+qhIuvtsj9d8eydpHeDvgb+ltJxPoewAVfWPIOl7th88rdwL+89VLGsJcC/63u3Z/kntckZB0r2A/wDuY3uP5oVkF9tHVi5na8oOX7tSAvq3gYNsX12znFFoMyuhpGfN9rjtEyuX91LgWNt/GPDY3WxXaUU391sXeAAlDlzRdO8t/L6LPaBLOhA4mjKg9FHgIcDBtVqBkn5EeVINTAFs+341yhml5q32DsCnm1PPpQzuvbFyOa8G3gz8gqnWmW3vUOn+32Nwl5RqltNX3smU/7U32d6xedKd38YLYdvaft70lfNO4Ou179vc++jmy3sCj6S0nAEeC5xme9aAvwblnWr78XOdq1TWIyn99P0NoY8v+L4TENAvbJ5cT6IMKv4rcLTt6tPj2tb34rGKNl40JD2b0gIUcIbtz7VQxpXAw1sabKPpw55R7YFeSefafpik823/v+bcBbZ3qnT/N9h+t6QPMfj/4DU1ymnKGsnzRtKNwIaU/vM/M/ViW20Ov6QvAS93k8G16do7tFZAl3RnYAPgG8BjmGrcbQycbPuvapTTV94ngPtTZm/1BkNd4++/aAdF+/R+uU+m/ENeqN6oYu2CpKcDj2oOT7P9pcpF9L81vTOwF2UKVnW2TwBOaOPefa6h0mDOIP0Bu+kOeVhzeE5vfKCy1garGpc1n1dUvOdMRvK8sV1tHcUstvaq6bh/AWxX8f7/ABwE3AfoHzS+gTLWUdsyYPs2ZgZNQgv9aMr0rm2AHSkpfE+z/dDK5byTEjA+2ZzaF1hh+59rljOg3G/Z3q3yPZ8FvIvyVlW00GpqyjmS0g/4Zdqb4TBo1s7fANVn7bQ5WDVqI3zePGrQedtnVCzjw5Q1G5+mvNjuQ9nn+NW1ymjKebXtD9W85wzlfAZ4jVvYM2ISAvo6wE6UaWp3ouzBt3ntX7zKSsqdbN/eHC+h9J9W66fVqqso16G8Ur+ihdknVwJPs33ZnBcvrJw3DzrfwgyHkczaae7dymDVtDK+Buxl+7fN8aaUwbgnVSyj97y5yvZvm3cem9d+cZL0xb7DO1M2lT+vhdk0z6K8kEPlLkRJj7P99ZkGYVsYfP0G5W9zDqs2hJ6+0HtPQpfLS4EDKQswLgAeAZxFaUnVtgnQm9Vytxbu/16m+k5vpcx53quFcn7RdjCH+oF7FutM62L5Fe2lrdiZqcGqh0iqMlg1zdJeMAew/RtJ1RaYNfe8vRmz2a7pI26F7af1H0vakgrz6QeUcyJlTn0bHk0ZcH3agMfcQrlvqXy/O0xCQD+Q0hXyHduPlfRAoI1A8g7g/ObVU5S+9NrdLXsAz2bV0e19gENq3LyvhbFC0nHA51m1BVDlH1PSB2wf1LTOBg3uLbilMc1XJJ3CqrN2llcuY8bBKqB2QL9N0la96Z3N4G/tqasvY3BDqGrLeYCVlC6rBet1RzYDr/2/n6pdiLbf3Hxua6e16eWd3ta9JyGg/9H2HyUh6U62L5dUZYJ/P5cFK6dRXjwEvNGVFy5QAuxvKQMvbax0629h/IEy372nZkvjE83n/6x0v1nZfv20WTuHtzFrhxYHq6Z5E/AtldWVUBoP+1UuYyQNoWkzdnrdPBfWuHdvbGlEA6+jmCLd+gvUJPShf46yR+lBlNbFb4D1bD+5hbI2pySy6p8bWnNw52LbVVovUV+bg1UDytqM0moWZQXs9ZXv35uCeQFlaumfak7B7CvnxX2HtwJX2/52zTKacnZk1T70NrKHTvwU6UXfQrf9zObLtzTdIXcDvlK7HEnvoryVv4S+RTJAtYAOnCnpwba/V/Geq5G0BWWMobcS8VvAgbZXVi5nV0p/YO9FsNfSqDqvflSzdigD7pdKqj5YNcBtwC8pA4nbN331Nf/XVqqkGP488DVJvwGurXh/AGwfU/ue0zUt55cz9Q7zk5IOb2FGSqtTPTWCVemLvoU+KpKuAHaw/ac5L57/vXsrHtelTL+6ihIw2lrx+DXgU0x1jbwAeL7tJ1Yu53LgH4Hz6MsW58oLjUY4a+fRg87X7vOcqX+79syQvvIeTdMQsn1Lc25T279ZwD2Pt723Vl/NW/1/upmBtovtm5rjDSm/r9rPm1anemoEq9IT0Bsqy773sv37Fu496hWPq721bunt9tleNWtgKyR92yWtaSc0QbDXv71Tr3/b9nNHWIfvLqQrQdJf2P7ZTP/bNf+ne78v239sju8MnOvKKRlGNdWzTYu+y2WE/gBcIOlUVn27veDluLUD9hB6O7r0ZoXsS5nqV9uoUrS2PWtnJLMp+oxkoH8OC+pK6BtnuJ6Sb/92SdtR0s6evNDKTXM0cHYzngYlX33VhGlwx1TPX1C6wFqNjWppVXpa6I1pgzt3GEUfYW2StgI+DOxCCVBnUvrQa78TGJSq1S0sKjl6wGnbfmnNckZllAP9s9RhQS30vvucRxms3BT4DiWtwR9sP3+h955WzkNZNTfR+TXv35TRG0e7lFVzrFQdQ1GLq9IT0PtIuguwle0rxl2XGD1Jh1AGwc/q9deOoMzq/dtDllsroH/X9kNUMm/exSX52PlukpvVohGkaW5zHG1aOa2tSp+ELehGQtLTKANUX2mOd5J00lgrtYYkHaO+TZQlbSrpqJbKeoqkN0j6t95HC2Vsp7I58MXN8Q6S/qV2OZSVu8+jdPGcI+m9kvZsoZw72D7d9km9YN44dU3vp7L5x1CXrmkZqxepXSj7sH65OVe1u6J5sfgF8DXgS005tRPnQZms0MZOWINs0vd1tVXp6UOf8hbKsu/TAGxfMI8nx2Kzg1dfWl61xQQg6TBK2tHHAkcAz6Hkp6jto8DrKVvEYfsiSZ+i8j6cto8CjpJ0b8omvq+jLPgZycKWPgsJtp8FHqq583jXyvF9EGVF9edsXyLpfpQ0tDUdCDyg9uypAVobR5vmP2hpVXoC+pRbbf9u2rTTSe2PWqf/bXsz/7WNv/Ujbe8g6SLbb5X0XtrJt7GB7XOm/W2qbgsHIOkIYHtKa/CblBeo2gO8w1jI/906KknTtpP02tVu3GTCrDHnubnP6cDpzVRCbF8F1A6AraZp7nNS89GaZibN7ZSpqtVXpSegT7lY0vOAJZK2pfxTnjnmOq2p91IWMfXSy+4FvL2Fcm5uPv9B0n0oM2naeFdzvaT7M5Wn/DlAG6s570GZe/xbSpK26115P9ER2IcyC2RdRvDOouluORK4K7CVyorOf7D9yorFXAWcJqnVNM22j2l7HK2ZSXOA7eNp4cUjAX3Kqyk5Nv5Eme53CvC2sdZoDdn+uKQVlBkUAp5l+9IWivpS01f/HkpL1pTukdpeBRwOPFDST4EfURZLVdVblSzpr4AnUaZlLrG9Re2y5rDGXS5NIHpX866p9vTBQT5A+V2d1JR/oWbIkb4AP2k+1m8+WtGMo/1nU8Y2knYCDmlhpfDXJL0OOA64Y/A9K0VjFRrhhtcDyr4TcGdX3Eh3QBkbUlLp3tjS/Z9KmYL3KMo0vLOAbzZ96zXLeQRwSe/nkLQRJSnY2c3x3Rf6t5J0N8p+r73gejolOFX9+/QWl2nVbfsudAu56tvWTMF8HGVeeO9nWWXD9UrltLYVZVrojWZRxOtYfePWttON1nQeqy4t7v3TqPm6do6VFZRFH59q+utbme7VvFjckXa415duu0ra4T57UKYtftB29bwnfT5CyeTXc1P/uUovvEdRdl3auzl+IeVvVXVjZeAalQ2PLWl9Sldl1RQNKhuavAF4ECX3DdDKc3NU42jbA68Edmvu/03gsBo3TkCf8hnKL/UI+vKSTBLbd/RfN631bel7ArRgH8oCmXP7gvtXXf9t3xcog2Ln0dKLBoDtV832uKSzbO9SoSj1/46aftXaz8X723523/FbVTIv1rY/8EFKDpSVwFcpXWQ1fZLSPfHUprwXA9dVLgNGN452DGW/0v9qjvdtzu0943cMy3Y+ynPrvHHXoeLP8jLge5QViN+gDF6e2mJ56wBPB35KmZHwVuDuFe9/8bh/p009zq90nxMpwWK95uNA4POV63oWsFvf8a6UBVNj/z2uwc9yXvP5or5zp7dQzgaUyQPnNh//DtyphXIuHObcmnys9S30vn7nL0p6JfA5Vh1Jb63fuUWj2uUJSTtQWulPBk6gtKZ2o2zptVOlYkaSdngItd557E9pnf1Lc89Tqb/Bxf7Ax5u+dCgv7gPTWyxE0x3yclbvqqyZlqG3r+vPJD2Fkga4jYHqp9h+E2VyBACS9qK8e6/pfEmPsP2dpoyHA1VyyK/1g6IaQUrLUdPoNjc4jzLF70jgBPctmZZ0ou0F9ddqxGmHh6hPleXyoyRpYwDbN0w7/2JXyFMk6UxKH/D0FMonLPTefWU8tSljS0qe/40p2SmrTvsb9Pdt428u6TLKRuS91AVbUcYdbmeB/9drfQvdff3OHTKSzQ0o6YavGvTAQoN546kV7lHTgpbLS3qDS66T/m3b7uD6KxJXC+R9DqT02y7UBrbfWOE+sznbZXbO7yirkquStAflHebmkv6r76GNaWEBG7B7C/cEEtDvoJJjebWRZzc5mCeJR7TLE/AySe92k2ZA0qbAP9mukmfFfdkhJT2Eqb/Nt10/Re8wXrjA7+/N/lix0IpUUCuXy5ckPdl29U27+5zZvJM+DjjR9ROXXUv5mzyd8k6j50bKBi5VucV02mt9l0uPpOMpf8D/bU7tC2xqe6/x1Wpx04Csei29Rf03ymrXXlqBZwCfsV0ll4tWz4O+CtfPhz52tf5Oze9uQ0pX2J9pKYe8pJ2ZWgV7KXCs7f+d9ZvmX8Z6tv8895WLVwJ6Y9BiiEldIDEqKmlAH9brO2+WTa+w/aDK5VwG/D9P7VhzF+C7tv+qcjmHAD+nbN0nSgbBjWy/u9L9v8jsLxxt7F06U11WezGeBCqba7+PsqXiksr3HskeuW1Kl8uU1kaeO+x/gVNVNqAw8FLq9MtOdzVlPn2v++tOwA9bKOdJXnVLvY9IOhuoEtApy8pHoklZMNt6ijqzKkpX2HS/A37sSnlwmoHdZ1Ja6PenzETbuca9pzmSAXvkTpK00Bttjjx3maTdgSc0h1+zfUoLZXyeMg3za5QXjicC3wJ+CfUGE5sZG4cCxzbl7Au8yvYja9x/lJo+589Sdq9vI49Pr5zvUFa49qaUPhi4kJLobH/bX61Qxo8oA/zH2z5rofebpZyR7JHbpgT0hubYyBm4oYXBmIkn6V6U1pKBc2z/soUyZp0/XWP6XVPO1pRVj7vSDL4CB9m+usb9+8rZFngHZQl4/1L2am/tm/wwvZW861BSARw7y6yXNS3nWOBtti9pjren5K5/G2UAc6cKZayysrYtKlvDLaH9PXJbk4A+pEmcg9w2SXtTMi2eRulv/Bvg9bY/O9v3tVCPE7zqMvdFTdK3KImz3g88jRJ0ZfvNLZX3KEoG0U0orfa32b6y0r1XW9/QO1dr7cOocrloRHvktil96MOrNc2rS95EGRT9JdzxxPs/StAYpSot2yZB20eAe9n+62YV7NNrzabpcxfbpzYtzx9Tppd+kxLkq1DZp/IplBeLrSk58j9JedFdDmxXqagrJH2E0k0FZZPl7zcJ1WrNGBlJLhfb1ee4j1oC+vDyVmZ160zrYvkV49mnttbfZiRb3QF/VNm55geSDqDkwLln5TJ+QMnj8x7b/QmmPqu6+cr/jrJ+4yBKo+dblKylf6beIqB72D5S0oGe2iHp9Er3RtILbP+vBuzwBPU30mhTAnosxFcknUJ5Ow+lddbmApO2jWSrO0rw24CSoOttlMD3osplvMj2t/pPSNrV9rdrrki1fTOl9f/eAQ//vlIxbedy2bD5POq9Y6tLQB9eulymsf16Sc+mDCIKONz258ZQlVp/m1FtdWfKXPf7MrXL/EeBmjOp/otVc65DyYNSe9FX6wO8wL83Scb+ialcLtVWcNruvSObNYGdpH+2/Y5a5bZhrR8U1ZC7/KjCLjLRDkl/W2l63P0oW909kpKd8EeUBSxVl2pLuoLStfM9yrRYoM6ScJU9Ph9JeRfw/r6HNgaeWXuh3KgHeMdpEiZGpIW+6i4/W1GeyKLMCPgJzabHCeark/Qs4F2U/l9Redl3X7bF1R6ib21AjWDesO0nqG+rO0ltJG+7zpUzBfZZn7Jh8/RNom8AntNCea0N8E5LlLWaNpKZzWHRv0tf6wO6m2yLkg4DTuolGWoysD1htu8N3g08zXbVLcf6jDrb4gnAQ2zf1Hfus8BDK5fzZklHUPKg9893PnHmbxlO36Dhx9pMAtWnzQHeZ1FmUm1KaWiN26LvzljrA3qfh9nev3dg+2RJbxtnhSbAL1oM5q1mpeunsgHIg4C7Ne86ejamnS38XgI8kNJ/3utyMVPJx9aYpA/YPgj4sKRBKXpr54s5iPYGeG+grHE4iRbS5q6BtNAnyPWS/oWSn8TACyjT8GKavqC3QtJxlGXZVVua08p7BGUw7K8oXQpLgJsqZvR7AOXdwCaUfuCeGym78dS2oyvvJN/nE83nUeWNaXOA9zBK2uf7sWrK4eqbnjfz9l9j+/2zXFZ756Lq1vpB0Z5mcPTNQG+O7hmUXVHSdz5Nk4xrJnbd7cdQ2YB6H8oTahmlBfiXLtuF1SxnlzZzhfSV81Hg/W3mWBmVNgd4+8r4iO1X1LrfLOWcZvsxbZfTpgT0WGO9ec1znatQzgrbyyRd1BsIlXRm7aRZfVkjV9HCC9RllKyBP6KlLfVGlQpW0rds71bznuMi6e2UzWCOA+4YR5mkXC5rfZdLr89xplzVLfQ5dsmgec3V5zoDf5C0PnCBpHdT5oZvOMf3rIkv9X19Z0rK1ja27mttC7I+o0oF29oA7xj0GgiH9J0zkFwuE2TUfY4Tr2+u89Jpy6U3pvRv1/ZCSkqBAyhBakvKDIiqPG1jY0mfpuSmqV3OKAZ7f2f75BGU09oA76gll0sH2D6v+Xx60wrsJS26whO+HVWLRj3X+Rm2P0jZ4OKtAJIOpKS6bdO2lLUJk+gbkt5D+6lg2xzgHalmNWr/ONrpwCEuG1RPhPShNyQ9hrLbztWU/sYtgRfbPmN8tVrcJN13FK3NQSv01MIWapraW7Q3i+LnwD9Pb7lPglGlgu3YAO8JwMVM7br1QsoLVvV3g21JQG9IOg94nu0rmuPtgE/brr2opDOa39HrKOlZ73i3VytoSNoXeB6wG/DNvoc2Bm61nYVfYzaKAd5RmS23+3hqNH9rfZdLn/V6wRzA9vclrTfbNwSfocwVPoJ2Bt7OpAyAbsaq2fxuBC6qVYgG74t5h0ma5TCGVLCjGOAdlZsl7dbLUtnMFLp5zHWalwT0KSskHcnUIOnzKTMEYma32v5IWzdvunN+DOyistXdw5qHLnOlDYgbg1K/3lENJmiWAyNOBTuq1bwj8grgmKYvXcCvKfneJ0a6XBrNDiuvory9F2Vh0X/b/tOs37gWk/QWykbNn2PVgbeqi7Ek7UWZhXQaY9zqLtYOkjYGcOX9V0chAT3WmMpu7NO1sXjlQuCJnrbVXa1UsJIeZ/vr0/K43GGS5lQvwgyFi95M3VM9LXRTtSZdLo0BK+uA6on6O6WXqXIE2t7q7tHA11k1j0vPpM2pTjfh/E38TkU9aaE3JF3OgJV1tpOgaxaS/prVd6v5eOUy3g3syKpb3V1k+401y4mYdGmhTxnVyrrOkPRm4DGUgL4c2IOySXDVgE5pJf8PU+MbhwOPqHXzLr3l7mm6pd7I6i+2kzTAO1KStqCkrtiV8j/3LeBA2yvHWrF5GMcO7YvVNyS9R9Iukh7S+xh3pRa55wCPB35u+yWUVvSdWijnibZPtP1a2//osm/pHhXvv1HzsYwy02Hz5mN/SkCcRJ8ELqPsuPVWyoK5c8dZoQlwNCX3+n0of/8vNucmRrpcGqNaWdclks6xvXOzKOuxlPnhF9t+UKX7vwJ4JSXv9Q/7HtoI+LbtF9Qop6+8rwLPtn1jc7wR8BnbEzfXWtJ5th86LUPl6bYfPe66LVZZWNQhXUjMMwYrJG1C2dDgPOD3wDkV7/8p4GTKrvIH952/saU89VsBt/Qd30JZBTuJenmIfibpKZSskVuMsT6T4HpJL2BqrGZfJmyTm7TQ+zT/+A9i1T7HQ2b+juiRtDWwse1qKzhHTdKbgL0p8+pNSZ97nO13jLVia0DSUynpErak9AtvTNmwpa3NqSeepK2ADwO7UP7+Z1J2MfrJWCs2DwnojWaT6A0oXQdHUPqHz7H992Ot2CIn6en0Zaez/cVx1mehmnGTv2kOz7B9ft9jm9peDJsVRwskHQMc1PsbN7uY/WftDU7alIDe6PU19n2+K3Ci7b8dd90WK0nvpCzH/2Rzal9ghe1/Hl+t2jMo6+Ni1QSnA23/tjneFHjvJAWnURuUwbONrJ5tSh/6lF4Snj9Iug+l72xUC2cm1ZOBnWzfDncEkfOBTgZ0JmDX9z479II5gO3fSJqYwDQm6/S/C2ta6BMVIyeqsi37UjPA9x7gu5Q+tI+OtUaTYRNKEiMo+zF22SS9nZ344DQG7wXOlPRZyt96b+Dt463S/KTLZYAmUdedJ2mnknGQtA/wLuAblNbroygbQhw71oq1ZMK6XF5EeafUS2C2F/B225+Y+btC0vaU7JoCTp20jTsS0BtNAqjjKLMafjjX9Ws7SetQBo6/SelHF3C27Z+PtWJrQNI2tgclGpt+3UT1p056cIr5S0BvSLovJUfIcymb3R4HHD9JU5ZGTdIZth8195WLW98inFNtP36W6+7e0vz3apqulRkt9vrHwiSgDyBpW+BfgefbbmMX+06Q9K+UweTjgJt65yctaEg6H/g88DLg/dMfn6RcLk1K496+qDDV79/bGi7ZQzssgyR9msUxe1Na6bcBbxhrhRa/l1ICxiunnZ+0oLEP8AzK82GiU6n2pzRuWuvb0rdQLrotLfSGpLOB9Sj7ZB5n+6oxV2nRk3QXSjDfjRLYvwkcZnui9mHskbRHVzJuSnoZcCBluf8FlOyUZ87WpRSTLwG9IemBti8fdz0miaTjgRtYdWHRJrb3Hl+t1lyzl+Sb6Vv5ChwyibOdJH2PMlj9Hds7SXogZen/c8dctWhRulwati9PLpd5e8C0beC+0cwWmlRHARdTut0AXkhJnzpwa7pF7o+2/ygJSXdq/r8fMO5KRbsS0Bsz5XIZa6UWv/MlPcL2dwAkPRz49pjrtBD3t/3svuO3SrpgXJVZoJXNQrnPA1+T9BtKxsXosHS5NJLLZf4kXQY8AOhN7dyKsqnC7ZQZFTuMq25rQtJZwOttf6s53pWSnGmX8dZsYSQ9mrKK9yu2b5nr+phcaaFPSS6X+Zu4jR/msD/w8aYvHeA3wIvHWJ8qbJ8+7jrEaCSgTxmUy+WIsdZokbP943HXoSbbFwI7Stq4Ob6h/3FJL7Z9zFgqFzGEdLkMkFwuMcgk5XKJtdNa30KXNOMMBknYPnGU9YlFbZLS58ZaaK0P6MDTZnnMQAJ69OTtbCxqCehwge0PStqtN7shYgZpoceits64K7AIvKT5/F9jrUVMgkmeYx9rgbV+UFTSpym7fC8F+vOg97LTTdRc6lg4SbsBOwMX2/7quOsTMay1PqADSLo3cArw9OmPdW1qXqxO0jm2d26+fjnwKuBzwN8CX7T9znHWL2JYCeix1uvfiUjSucCTbV8naUNKcqsHj7eGEcPJoGijWeb9FuC+lN9LNgRYe6wjaVPKmJJsXwdg+yZJt463ahHDS0CfciTwj8B5lM0tYu1xN8rfXYAl3dv2z5t8PpnZEhMjXS4NSWfbfvi46xGLh6QNgHsNs4F0xGKQgN6Q9E5gCWUh0Z96521/d2yVirGTdFfbvx93PSKGkYDekPSNAadt+3Ejr0wsGpJ+YnurcdcjYhjpQ2/Yfuy46xDjIem1Mz0E3HWUdYlYiKwUbUi6m6T3SVrRfLy3Ly92dNt/AJsCG037uCt5jsQESZdLQ9IJlP0ke/muXwjsaHsS95OMeZB0JvBq2+cNeOwa21uOoVoR85aA3pB0ge2d5joX3dNsnvzr3vzzaY/dy/YvxlCtiHnL28kpNzc5PIA7FhrdPMv10RG2rxgUzJvHEsxjYqSF3pC0E6W7ZZX9JG1fNLZKxUg0880PoOQ7/xCwD/As4HLgkExbjEmRgN5otp17DnB/YBPgd5Rpi4eMs17RPknHA9cAdwEeAFwGHE/Z/OTetl84xupFDC3TFqd8AfgtZYPon463KjFi29neW5KAnwFPsG1J3wQuHHPdIoaWgD5lC9u7j7sSMT5NEF/u5m1rc5y3sDExMig65UxJSZO6dlrRJOLC9kt7JyXdH7hxbLWKmKf0oTckXQr8JfAjSi6X7FgUSJLzJIkJkS6XKXuMuwIxHpLmWjx24kgqErFAaaHHWk/S0c2X9wQeCXy9OX4scFpWC8ekSAs91nq2XwIg6UvA9rZ/1hz/BXDoOOsWMR8ZFI2YsnUvmDd+AWw3rspEzFda6BFTTpN0CvBpyqrRfYBBefIjFqX0oUf0kfRM4FHN4Rm2PzfO+kTMR1roEas6E7iV0kI/Z8x1iZiX9KFHNCTtTQnizwH2Bs6W9Jzx1ipieOlyiWhIuhB4ou1fNsdLgf+zveN4axYxnLTQI6as0wvmjV+R50hMkPShR0z5St8sF4DnAsvHWJ+IeUmXS0QfSc8GdqXk8sksl5goCeix1mta5V8BTrZ9+bjrE7GmEtBjrSfp3sDuzcd2wNmUAH9qtp+LSZKAHtFH0jrAwynZNx9P2Sj8q7bfPdaKRQwhAT1iFpI2A55k+5PjrkvEXBLQIwBJTwKeAWxOWSV6LfB526eMs14R85GAHms9SR+g9J1/HFjZnN4CeBHwA9sHjqlqEfOSgB5rPUnft71amlxJAr5ve9sxVCti3rIKLgL+KGnnAecfBvxx1JWJWFNZKRoBfwd8RNJGTHW5bAnc0DwWMRHS5RLRaOajb05ZJbrS9s/HXKWIeUmXSwQgaSvgj7bPA64HdpP0oDFXK2JeEtBjrSfpYOB04DuSXkZZJboHcLyk1461chHzkC6XWOtJugRYBmwAXA3cz/Z1kjYEzrb91+OsX8SwMigaAbfZvlnSLZSl/r8CsH1TmbkYMRnSQo+1nqSPAesDGwJ/oOwp+hXgccBGtvceX+0ihpeAHms9SesCe1GW/H8W2Bl4HvAT4FDbN42xehFDS0CPiOiIzHKJtZ6kjSW9Q9InJD1v2mP/Pa56RcxXAnoEHE1ZTHQCsI+kEyTdqXnsEeOrVsT8JKBHwP1tH2z787afDnwX+Lqke4y7YhHzkWmLEXAnSevYvh3A9tslrQTOAO463qpFDC8t9Aj4ImWK4h1sHwP8E3DLWGoUsQYyyyUioiPS5RJrvbnytdh+36jqErEQCegRsFHz+QGUTS1Oao6fRulHj5gI6XKJaEj6KvBs2zc2xxsBn7G9+3hrFjGcDIpGTNmKVQdBbwG2Hk9VIuYvXS4RUz4BnCPpc5S8Ls8CPj7eKkUML10uEX0kPQR4CiWgf9n2+WOuUsTQ0uUS0ZD0GuAYyjvX9YFjJL16vLWKGF5a6BENSRcBu/TS5TY7Fp1le4fx1ixiOGmhR0wRcFvf8W3NuYiJkEHRiClHA2c3g6IAzwCOHF91IuYnXS4RfZpB0d0oLfMzMigakyQBPSKiI9KHHhHREQnoEREdkYAeEdERCegRER2RgB4R0RH/H1v6kSj9FuAgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_values = pd.Series(chi_scores[1],index = X.columns)\n",
    "p_values.sort_values(ascending = False , inplace = True)\n",
    "p_values.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since ash has higher the p-value,\n",
    "it says that this variables is independent of the repsone and can not be considered for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71               15.6      127.0           2.80   \n",
       "1    13.20        1.78               11.2      100.0           2.65   \n",
       "2    13.16        2.36               18.6      101.0           2.80   \n",
       "3    14.37        1.95               16.8      113.0           3.85   \n",
       "4    13.24        2.59               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  target  \n",
       "0                          3.92   1065.0       0  \n",
       "1                          3.40   1050.0       0  \n",
       "2                          3.17   1185.0       0  \n",
       "3                          3.45   1480.0       0  \n",
       "4                          2.93    735.0       0  "
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drop_1 = df.drop('ash', axis=1)\n",
    "df_drop_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_drop_1.iloc[:, :-1]  # Select all columns except the last one\n",
    "y = df_drop_1.iloc[:, -1]   # Select the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "# Create Decision Tree classifer object\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "model = model.fit(x_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation using Accuracy score\n",
    "from sklearn import metrics\n",
    "\n",
    "# Calculate accuracy using sklearn's recall_score function\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate precision\n",
    "precision = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate recall using sklearn's recall_score function\n",
    "recall =metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate F1 score using sklearn's f1_score function\n",
    "f1 = metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate mean squared error using sklearn's mean_squared_error function\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "Precision: 1.0\n",
      "Recall: 0.9\n",
      "F1 score: 0.9\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",round(accuracy,1))\n",
    "print(\"Precision:\",round(precision, 1))\n",
    "print(\"Recall:\", round(recall, 1))\n",
    "print(\"F1 score:\", round(f1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71               15.6      127.0           2.80   \n",
       "1    13.20        1.78               11.2      100.0           2.65   \n",
       "2    13.16        2.36               18.6      101.0           2.80   \n",
       "3    14.37        1.95               16.8      113.0           3.85   \n",
       "4    13.24        2.59               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06             2.29             5.64  1.04   \n",
       "1        2.76             1.28             4.38  1.05   \n",
       "2        3.24             2.81             5.68  1.03   \n",
       "3        3.49             2.18             7.80  0.86   \n",
       "4        2.69             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  target  \n",
       "0                          3.92   1065.0       0  \n",
       "1                          3.40   1050.0       0  \n",
       "2                          3.17   1185.0       0  \n",
       "3                          3.45   1480.0       0  \n",
       "4                          2.93    735.0       0  "
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drop_2 = df_drop_1.drop('nonflavanoid_phenols', axis=1)\n",
    "df_drop_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_drop_2.iloc[:, :-1]  # Select all columns except the last one\n",
    "y = df_drop_2.iloc[:, -1]   # Select the last column\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "# Create Decision Tree classifer object\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "model = model.fit(x_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation using Accuracy score\n",
    "from sklearn import metrics\n",
    "\n",
    "# Calculate accuracy using sklearn's recall_score function\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate precision\n",
    "precision = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate recall using sklearn's recall_score function\n",
    "recall =metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate F1 score using sklearn's f1_score function\n",
    "f1 = metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate mean squared error using sklearn's mean_squared_error function\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "Precision: 0.9\n",
      "Recall: 0.9\n",
      "F1 score: 0.9\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",round(accuracy,1))\n",
    "print(\"Precision:\",round(precision, 1))\n",
    "print(\"Recall:\", round(recall, 1))\n",
    "print(\"F1 score:\", round(f1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means featrue selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs K-means clustering with different values of K and then selects the features with the largest and smallest differences in means between the clusters. It then trains a decision tree classifier on the selected features and computes the accuracy of the classifier on a test set.\n",
    "\n",
    "By comparing the accuracies obtained using the features with the largest and smallest differences in means between the clusters, this code helps to test the effectiveness of the K-means feature selection method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_features:  13\n",
      "\n",
      "K=5\n",
      "Number of features in the dataset: 13\n",
      "Number of features in the selected dataset (largest diff): 5\n",
      "Accuracy (largest diff): 97.2%\n",
      "Number of features in the selected dataset (smallest diff): 5\n",
      "Accuracy (smallest diff): 77.8%\n",
      "\n",
      "K=6\n",
      "Number of features in the dataset: 13\n",
      "Number of features in the selected dataset (largest diff): 6\n",
      "Accuracy (largest diff): 97.2%\n",
      "Number of features in the selected dataset (smallest diff): 6\n",
      "Accuracy (smallest diff): 75.0%\n",
      "\n",
      "K=7\n",
      "Number of features in the dataset: 13\n",
      "Number of features in the selected dataset (largest diff): 7\n",
      "Accuracy (largest diff): 97.2%\n",
      "Number of features in the selected dataset (smallest diff): 7\n",
      "Accuracy (smallest diff): 77.8%\n",
      "\n",
      "K=8\n",
      "Number of features in the dataset: 13\n",
      "Number of features in the selected dataset (largest diff): 8\n",
      "Accuracy (largest diff): 97.2%\n",
      "Number of features in the selected dataset (smallest diff): 8\n",
      "Accuracy (smallest diff): 88.9%\n",
      "\n",
      "K=9\n",
      "Number of features in the dataset: 13\n",
      "Number of features in the selected dataset (largest diff): 9\n",
      "Accuracy (largest diff): 97.2%\n",
      "Number of features in the selected dataset (smallest diff): 9\n",
      "Accuracy (smallest diff): 86.1%\n",
      "\n",
      "K=10\n",
      "Number of features in the dataset: 13\n",
      "Number of features in the selected dataset (largest diff): 10\n",
      "Accuracy (largest diff): 97.2%\n",
      "Number of features in the selected dataset (smallest diff): 10\n",
      "Accuracy (smallest diff): 94.4%\n",
      "\n",
      "K=11\n",
      "Number of features in the dataset: 13\n",
      "Number of features in the selected dataset (largest diff): 11\n",
      "Accuracy (largest diff): 94.4%\n",
      "Number of features in the selected dataset (smallest diff): 11\n",
      "Accuracy (smallest diff): 94.4%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# Load the dataset from scikit-learn\n",
    "wine = load_wine()\n",
    "\n",
    "# Convert the dataset into a pandas DataFrame\n",
    "data = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "\n",
    "# Split the input features and target variable\n",
    "X = data.iloc[:, :]\n",
    "y = wine.target\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = X.columns.tolist()\n",
    "number_of_features = X.shape[1]\n",
    "print(\"number_of_features: \",number_of_features)\n",
    "\n",
    "for k in range(5, 12):\n",
    "    print(f\"\\nK={k}\")\n",
    "    \n",
    "    # Perform K-means clustering with K clusters\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "\n",
    "    # Compute the mean value of each feature for each cluster\n",
    "    cluster_means = [np.mean(X[kmeans.labels_ == i], axis=0) for i in range(kmeans.n_clusters)]\n",
    "\n",
    "    # Compute the absolute difference in means between clusters for each feature\n",
    "    diff_means = np.abs(np.diff(cluster_means, axis=0))\n",
    "\n",
    "    # Select the features with the largest difference in means between clusters\n",
    "    selected_features = np.argsort(np.sum(diff_means, axis=0))[::-1][:k]\n",
    "    \n",
    "    # Select the features with the smallest difference in means between clusters\n",
    "    selected_features_smallest = np.argsort(np.sum(diff_means, axis=0))[:k]\n",
    "\n",
    "    # Filter the input data to keep only the selected features\n",
    "    X_selected = X.iloc[:, selected_features]\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a decision tree classifier on the training set\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set and compute accuracy\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)*100\n",
    "\n",
    "    print(f\"Number of features in the dataset: {number_of_features}\")\n",
    "    print(f\"Number of features in the selected dataset (largest diff): {len(selected_features)}\")\n",
    "    print(f\"Accuracy (largest diff): {round(accuracy,1)}%\")\n",
    "    \n",
    "    # Filter the input data to keep only the selected features\n",
    "    X_selected_smallest = X.iloc[:, selected_features_smallest]\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train_smallest, X_test_smallest, y_train_smallest, y_test_smallest = train_test_split(X_selected_smallest, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a decision tree classifier on the training set\n",
    "    clf_smallest = DecisionTreeClassifier(random_state=42)\n",
    "    clf_smallest.fit(X_train_smallest, y_train_smallest)\n",
    "\n",
    "    # Make predictions on the test set and compute accuracy\n",
    "    y_pred_smallest = clf_smallest.predict(X_test_smallest)\n",
    "    accuracy_smallest = accuracy_score(y_test_smallest, y_pred_smallest)*100\n",
    "\n",
    "    print(f\"Number of features in the selected dataset (smallest diff): {len(selected_features_smallest)}\")\n",
    "    print(f\"Accuracy (smallest diff): {round(accuracy_smallest,1)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features in the dataset:  13\n",
      "k =  5 :\n",
      "Top 5 features with highest variance Accuracy: 86.1\n",
      "Top 5 features with lowest variance Accuracy: 83.3\n",
      "k =  6 :\n",
      "Top 6 features with highest variance Accuracy: 94.4\n",
      "Top 6 features with lowest variance Accuracy: 91.7\n",
      "k =  7 :\n",
      "Top 7 features with highest variance Accuracy: 94.4\n",
      "Top 7 features with lowest variance Accuracy: 88.9\n",
      "k =  8 :\n",
      "Top 8 features with highest variance Accuracy: 97.2\n",
      "Top 8 features with lowest variance Accuracy: 86.1\n",
      "k =  9 :\n",
      "Top 9 features with highest variance Accuracy: 94.4\n",
      "Top 9 features with lowest variance Accuracy: 86.1\n",
      "k =  10 :\n",
      "Top 10 features with highest variance Accuracy: 97.2\n",
      "Top 10 features with lowest variance Accuracy: 94.4\n",
      "k =  11 :\n",
      "Top 11 features with highest variance Accuracy: 94.4\n",
      "Top 11 features with lowest variance Accuracy: 94.4\n",
      "k =  12 :\n",
      "Top 12 features with highest variance Accuracy: 94.4\n",
      "Top 12 features with lowest variance Accuracy: 94.4\n",
      "k =  13 :\n",
      "Top 13 features with highest variance Accuracy: 94.4\n",
      "Top 13 features with lowest variance Accuracy: 94.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# Load the wine dataset from scikit-learn\n",
    "wine = load_wine()\n",
    "\n",
    "X = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "y = pd.Series(wine.target)\n",
    "number_of_features = X.shape[1]\n",
    "print(\"number of features in the dataset: \",number_of_features)\n",
    "\n",
    "# Fit K-means clustering to the data\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Get the cluster labels and centroids\n",
    "labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Compute the variance of each feature within each cluster\n",
    "variances = np.zeros((3, X.shape[1]))\n",
    "for i in range(3):\n",
    "    cluster_data = X[labels == i]\n",
    "    variances[i] = np.var(cluster_data, axis=0)\n",
    "\n",
    "# Select the features with the highest variance within the cluster with the most data points\n",
    "most_common_cluster = np.argmax(np.bincount(labels))\n",
    "\n",
    "for k in range(5, number_of_features+1):\n",
    "    # select the top k features with highest variance\n",
    "    selected_features = np.argsort(variances[most_common_cluster])[::-1][:k]\n",
    "    # select the top k features with lowest variance\n",
    "    low_selected_features = np.argsort(variances[most_common_cluster])[:k]\n",
    "\n",
    "    # Use the selected features to transform the data\n",
    "    X_selected = X.iloc[:, selected_features]\n",
    "    low_X_selected = X.iloc[:, low_selected_features]\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a decision tree classifier on the training set\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set and compute accuracy for top k features with highest variance\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)*100\n",
    "    print(\"k = \",k,\":\")\n",
    "    print(f\"Top {k} features with highest variance Accuracy:\", round(accuracy,1))\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(low_X_selected, y, test_size=0.2, random_state=42)\n",
    "    # Train a decision tree classifier on the training set\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Make predictions on the test set and compute accuracy for top k features with lowest variance\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)*100\n",
    "    print(f\"Top {k} features with lowest variance Accuracy:\", round(accuracy,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# diabetes dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data - diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "#loading dataset\n",
    "#df = pd.read_csv(\"C:\\\\Users\\\\linor\\\\Desktop\\\\project\\\\diabetes.csv\")\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]  # Select all columns except the last one\n",
    "y = df.iloc[:, -1]   # Select the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  \n",
       "0                       0.627   50  \n",
       "1                       0.351   31  \n",
       "2                       0.672   32  \n",
       "3                       0.167   21  \n",
       "4                       2.288   33  \n",
       "..                        ...  ...  \n",
       "763                     0.171   63  \n",
       "764                     0.340   27  \n",
       "765                     0.245   30  \n",
       "766                     0.349   47  \n",
       "767                     0.315   23  \n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      1\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "763    0\n",
       "764    0\n",
       "765    0\n",
       "766    1\n",
       "767    0\n",
       "Name: Outcome, Length: 768, dtype: int64"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.3\n",
      "precision: 0.8\n",
      "Recall:  0.8\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "model = model.fit(x_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)*100\n",
    "\n",
    "# Calculate precision\n",
    "precision = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate recall using sklearn's recall_score function\n",
    "recall =metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate F1 score using sklearn's f1_score function\n",
    "f1 = metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate mean squared error using sklearn's mean_squared_error function\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "print(\"Accuracy:\",round(accuracy,1))\n",
    "print(\"precision:\",round(precision,1))\n",
    "print(\"Recall: \",round(recall,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chisquared test - diabetes_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "chi_scores = chi2(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 111.51969064, 1411.88704064,   17.60537322,   53.10803984,\n",
       "        2175.56527292,  127.66934333,    5.39268155,  181.30368904]),\n",
       " array([4.55261043e-026, 5.48728628e-309, 2.71819252e-005, 3.15697650e-013,\n",
       "        0.00000000e+000, 1.32590849e-029, 2.02213728e-002, 2.51638830e-041]))"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = pd.Series(chi_scores[1],index = X.columns)\n",
    "p_values.sort_values(ascending = False , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_values.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
      "       'BMI', 'DiabetesPedigreeFunction', 'Age'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since DiabetesPedigreeFunction has higher the p-value,\n",
    "it says that this variables is independent of the repsone and can not be considered for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  Age  \\\n",
       "0            6      148             72             35        0  33.6   50   \n",
       "1            1       85             66             29        0  26.6   31   \n",
       "2            8      183             64              0        0  23.3   32   \n",
       "3            1       89             66             23       94  28.1   21   \n",
       "4            0      137             40             35      168  43.1   33   \n",
       "\n",
       "   Outcome  \n",
       "0        1  \n",
       "1        0  \n",
       "2        1  \n",
       "3        0  \n",
       "4        1  "
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drop_1 = df.drop('DiabetesPedigreeFunction', axis=1)\n",
    "df_drop_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.2\n",
      "precision: 0.7\n",
      "Recall:  0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X = df_drop_1.iloc[:, :-1]  # Select all columns except the last one\n",
    "y = df_drop_1.iloc[:, -1]   # Select the last column\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "model = model.fit(x_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)*100\n",
    "\n",
    "# Calculate precision\n",
    "precision = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate recall using sklearn's recall_score function\n",
    "recall =metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate F1 score using sklearn's f1_score function\n",
    "f1 = metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate mean squared error using sklearn's mean_squared_error function\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "print(\"Accuracy:\",round(accuracy,1))\n",
    "print(\"precision:\",round(precision,1))\n",
    "print(\"Recall: \",round(recall,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_features:  8\n",
      "\n",
      "K=5\n",
      "Number of features in the dataset: 8\n",
      "Number of features in the selected dataset: 5\n",
      "Accuracy: 64.3%\n",
      "Number of features in the selected dataset (smallest diff): 5\n",
      "Accuracy (smallest diff): 58.4%\n",
      "\n",
      "K=6\n",
      "Number of features in the dataset: 8\n",
      "Number of features in the selected dataset: 6\n",
      "Accuracy: 66.9%\n",
      "Number of features in the selected dataset (smallest diff): 6\n",
      "Accuracy (smallest diff): 55.8%\n",
      "\n",
      "K=7\n",
      "Number of features in the dataset: 8\n",
      "Number of features in the selected dataset: 7\n",
      "Accuracy: 67.5%\n",
      "Number of features in the selected dataset (smallest diff): 7\n",
      "Accuracy (smallest diff): 72.1%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset from a CSV file\n",
    "#data = pd.read_csv(\"C:\\\\Users\\\\linor\\\\Desktop\\\\project\\\\diabetes.csv\")\n",
    "data = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "# Split the input features and target variable\n",
    "X = data.iloc[:, :-1]  # Select all columns except the last one\n",
    "y = data.iloc[:, -1]   # Select the last column\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = X.columns.tolist()\n",
    "number_of_features = X.shape[1]\n",
    "print(\"number_of_features: \",number_of_features)\n",
    "\n",
    "for k in range(5, 8):\n",
    "    print(f\"\\nK={k}\")\n",
    "    \n",
    "    # Perform K-means clustering with K clusters\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "\n",
    "    # Compute the mean value of each feature for each cluster\n",
    "    cluster_means = [np.mean(X[kmeans.labels_ == i], axis=0) for i in range(kmeans.n_clusters)]\n",
    "\n",
    "    # Compute the absolute difference in means between clusters for each feature\n",
    "    diff_means = np.abs(np.diff(cluster_means, axis=0))\n",
    "\n",
    "    # Select the features with the largest difference in means between clusters\n",
    "    selected_features = np.argsort(np.sum(diff_means, axis=0))[::-1][:k]\n",
    "    \n",
    "    # Select the features with the smallest difference in means between clusters\n",
    "    selected_features_smallest = np.argsort(np.sum(diff_means, axis=0))[::-1][-k:]\n",
    "\n",
    "    # Filter the input data to keep only the selected features\n",
    "    X_selected = X.iloc[:, selected_features]\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a decision tree classifier on the training set\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set and compute accuracy\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)*100\n",
    "\n",
    "    print(f\"Number of features in the dataset: {number_of_features}\")\n",
    "    print(f\"Number of features in the selected dataset: {len(selected_features)}\")\n",
    "    print(f\"Accuracy: {round(accuracy,1)}%\")\n",
    "    \n",
    "    # Filter the input data to keep only the selected features\n",
    "    X_selected_smallest = X.iloc[:, selected_features_smallest]\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train_smallest, X_test_smallest, y_train_smallest, y_test_smallest = train_test_split(X_selected_smallest, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a decision tree classifier on the training set\n",
    "    clf_smallest = DecisionTreeClassifier(random_state=42)\n",
    "    clf_smallest.fit(X_train_smallest, y_train_smallest)\n",
    "\n",
    "    # Make predictions on the test set and compute accuracy\n",
    "    y_pred_smallest = clf_smallest.predict(X_test_smallest)\n",
    "    accuracy_smallest = accuracy_score(y_test_smallest, y_pred_smallest)*100\n",
    "\n",
    "    print(f\"Number of features in the selected dataset (smallest diff): {len(selected_features_smallest)}\")\n",
    "    print(f\"Accuracy (smallest diff): {round(accuracy_smallest,1)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature selection by clustering - diabetes_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features in the dataset:  8\n",
      "k =  4 :\n",
      "Accuracy with top 4 features with highest variance: 63.6\n",
      "Accuracy with top 4 features with lowest variance: 58.4\n",
      "k =  5 :\n",
      "Accuracy with top 5 features with highest variance: 64.9\n",
      "Accuracy with top 5 features with lowest variance: 58.4\n",
      "k =  6 :\n",
      "Accuracy with top 6 features with highest variance: 67.5\n",
      "Accuracy with top 6 features with lowest variance: 57.8\n",
      "k =  7 :\n",
      "Accuracy with top 7 features with highest variance: 67.5\n",
      "Accuracy with top 7 features with lowest variance: 64.3\n",
      "k =  8 :\n",
      "Accuracy with top 8 features with highest variance: 75.3\n",
      "Accuracy with top 8 features with lowest variance: 76.6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data from a CSV file into a pandas DataFrame\n",
    "#df = pd.read_csv(\"C:\\\\Users\\\\linor\\\\Desktop\\\\project\\\\diabetes.csv\")\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "X = df.iloc[:, :-1]  # Select all columns except the last one\n",
    "y = df.iloc[:, -1]   # Select the last column\n",
    "print(\"number of features in the dataset: \", X.shape[1])\n",
    "# Fit K-means clustering to the data\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Get the cluster labels and centroids\n",
    "labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Compute the variance of each feature within each cluster\n",
    "variances = np.zeros((3, X.shape[1]))\n",
    "for i in range(3):\n",
    "    cluster_data = X[labels == i]\n",
    "    variances[i] = np.var(cluster_data, axis=0)\n",
    "    #print(cluster_data)\n",
    "\n",
    "# Select the features with the highest variance within the cluster with the most data points\n",
    "most_common_cluster = np.argmax(np.bincount(labels))\n",
    "selected_features = np.argsort(variances[most_common_cluster])[::-1] # select features with highest variance\n",
    "low_selected_features = np.argsort(variances[most_common_cluster])  # select features with lowest variance\n",
    "\n",
    "# Loop over k values and print the accuracy for each\n",
    "for k in range(4, 9):\n",
    "    # Select the top k features with highest variance\n",
    "    selected_k_features = selected_features[:k]\n",
    "    X_selected_k = X.iloc[:, selected_k_features]\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected_k, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a decision tree classifier on the training set\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set and compute accuracy\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy_high_var = accuracy_score(y_test, y_pred)*100\n",
    "\n",
    "    # Select the top k features with lowest variance\n",
    "    low_selected_k_features = low_selected_features[:k]\n",
    "    X_low_selected_k = X.iloc[:, low_selected_k_features]\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_low_selected_k, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a decision tree classifier on the training set\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set and compute accuracy\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy_low_var = accuracy_score(y_test, y_pred)*100\n",
    "\n",
    "    # Print the accuracy for the current k value\n",
    "    print(\"k = \",k,\":\")\n",
    "    print(f\"Accuracy with top {k} features with highest variance: {round(accuracy_high_var, 1)}\")\n",
    "    print(f\"Accuracy with top {k} features with lowest variance: {round(accuracy_low_var, 1)}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example data\n",
    "# Breast cancer dataset\n",
    "dataset1 = np.array([94.7, 81.6, 93.9, 93])\n",
    "# wine dataset\n",
    "dataset2 = np.array([90, 90, 94.4, 94.4])\n",
    "# diabetes dataset\n",
    "dataset3 = np.array([75.3, 68.2, 67.5, 67.5])\n",
    "\n",
    "# Set the names of the datasets\n",
    "dataset_names = ['Dataset 1', 'Dataset 2', 'Dataset 3']\n",
    "\n",
    "# Set the names of the values\n",
    "value_names = ['origin', 'chi squared test', 'k-means_1', 'k-means_2']\n",
    "\n",
    "# Set the positions of the bars on the x-axis\n",
    "x_pos = np.arange(len(dataset_names))\n",
    "\n",
    "# Set the width of the bars\n",
    "bar_width = 0.2\n",
    "\n",
    "# Create a bar chart for each value\n",
    "for i, value_name in enumerate(value_names):\n",
    "    # Set the y-values for the current value\n",
    "    values = [dataset1[i], dataset2[i], dataset3[i]]\n",
    "    \n",
    "    # Set the positions of the bars for the current value\n",
    "    cur_x_pos = [x + (i * bar_width) for x in x_pos]\n",
    "    \n",
    "    # Create a bar chart for the current value\n",
    "    plt.bar(cur_x_pos, values, width=bar_width, label=value_name)\n",
    "\n",
    "# Set the labels and title for the chart\n",
    "plt.xlabel('Dataset')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison of Values for Three Datasets')\n",
    "\n",
    "# Set the x-axis tick marks and labels\n",
    "plt.xticks([x + bar_width for x in x_pos], dataset_names)\n",
    "\n",
    "# Add a legend to the chart\n",
    "plt.legend()\n",
    "\n",
    "# Show the chart\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
